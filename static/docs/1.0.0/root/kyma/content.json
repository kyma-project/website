{
  "id": "kyma",
  "displayName": "Kyma",
  "description": "Overall documentation for Kyma",
  "type": "Root",
  "docs": [
    {
      "order": "001-overview",
      "title": "Overview",
      "type": "Overview",
      "source":
        "<p>Kyma is the easiest and fastest way to integrate and extend products in a cloud-native way. Kyma is designed as a centerpiece that brings together different external products and increases their agility and customizability.</p>\n<p>Kyma allows you to extend and customize the functionality of your products in a quick and modern way, using serverless computing and microservice architecture. The extensions and customizations you create are decoupled from the core applications, which means that deployments are quick, scaling is independent from the core applications, and the changes you make can be easily reverted without causing downtime of the production system.</p>\n<p>Living outside of the core product, Kyma allows you to be completely language-agnostic and customize your solution using the technology stack you want to use, not the one the core product dictates. Additionally, Kyma follows the &quot;batteries included&quot; principle and comes with all of the &quot;plumbing code&quot; ready to use, allowing you to focus entirely on writing the domain code and business logic.</p>\n<p>Out of the box, Kyma comes with:</p>\n<ul>\n<li>Security (Service Identity, TLS, Role Based Access Control)</li>\n<li>Resilience</li>\n<li>Telemetry and reporting</li>\n<li>Traffic routing</li>\n<li>Fault injection</li>\n</ul>\n<p>When it comes to technology stacks, Kyma is all about the latest, most modern, and most powerful technologies available. The entire solution is containerized and runs on a <a href=\"https://kubernetes.io/\" target=\"_blank\">Kubernetes</a> cluster hosted in the <a href=\"https://azure.microsoft.com/\" target=\"_blank\">Microsoft Azure</a> cloud environment. Customers can access the cluster easily using a single sign on solution based on the <a href=\"https://github.com/coreos/dex\" target=\"_blank\">Dex</a> identity provider integrated with any <a href=\"https://openid.net/connect/\" target=\"_blank\">OpenID Connect</a>-compliant identity provider or a SAML2-based enterprise authentication server.</p>\n<p>The communication between services is handled by the <a href=\"https://istio.io/\" target=\"_blank\">Istio</a> service mesh component, which enables security, monitoring, and tracing without the need to change the application code.\nBuild your applications using services provisioned by one of the many Service Brokers compatible with the <a href=\"https://www.openservicebrokerapi.org/\" target=\"_blank\">Open Service Broker API</a>, and monitor the speed and efficiency of your solutions using <a href=\"https://prometheus.io/\" target=\"_blank\">Prometheus</a>, which gives you the most accurate and up-to-date tracing and telemetry data.</p>\n<p>Using <a href=\"https://github.com/kubernetes/minikube\" target=\"_blank\">Minikube</a>, you can run Kyma locally, develop, and test your solutions on a small scale before you push them to a cluster. Follow the Getting Started guides to <a href=\"031-gs-local-installation.md\">install Kyma locally</a> and <a href=\"032-gs-sample-service-deployment-to-local.md\">deploy a sample service</a>.</p>\n"
    },
    {
      "order": "002-components",
      "title": "Components",
      "type": "Details",
      "source":
        "<p>Kyma is built on the foundation of the best and most advanced open-source projects which make up the components readily available for customers to use.\nThis section describes the Kyma components.</p>\n<h2 id=\"service-catalog\">Service Catalog</h2>\n<p>The Service Catalog lists all of the services available to Kyma users through the registered Service Brokers. Using the Service Catalog, you can provision new services in the\nKyma <a href=\"https://kubernetes.io/\" target=\"_blank\">Kubernetes</a> cluster and create bindings between the provisioned service and an application.</p>\n<h2 id=\"service-brokers\">Service Brokers</h2>\n<p>Service Brokers are <a href=\"https://www.openservicebrokerapi.org/\" target=\"_blank\">Open Service Broker API</a>-compatible servers that manage the lifecycle of one or more services. Each Service Broker registered in Kyma presents the services it offers to the Service Catalog. You can provision these services on a cluster level through the Service Catalog. Out of the box, Kyma comes with three Service Brokers.\nYou can register more <a href=\"https://www.openservicebrokerapi.org/\" target=\"_blank\">Open Service Broker API</a>-compatible Service Brokers in Kyma and provision the services they offer using the Service Catalog.</p>\n<h2 id=\"application-connector\">Application Connector</h2>\n<p>The Application Connector is a proprietary Kyma solution. This endpoint is the Kyma side of the connection between Kyma and the external solutions. The Application Connector allows you to register the APIs and the Event Catalog, which lists all of the available events, of the connected solution. Additionally, the Application Connector proxies the calls from Kyma to external APIs in a secure way.</p>\n<h2 id=\"event-bus\">Event Bus</h2>\n<p>Kyma Event Bus receives Events from external solutions and triggers the business logic created with lambda functions and services in Kyma. The Event Bus is based on the <a href=\"https://nats.io/\" target=\"_blank\">NATS Streaming</a> open source messaging system for cloud-native applications.</p>\n<h2 id=\"service-mesh\">Service Mesh</h2>\n<p>The Service Mesh is an infrastructure layer that handles service-to-service communication, proxying, service discovery, traceability, and security independent of the code of the services. Kyma uses the <a href=\"https://istio.io/\" target=\"_blank\">Istio</a> Service Mesh that enforces RBAC (Role Based Access Control) in the cluster. <a href=\"https://github.com/coreos/dex\" target=\"_blank\">Dex</a> handles the identity management and identity provider integration. It allows you to integrate any <a href=\"https://openid.net/connect/\" target=\"_blank\">OpenID Connect</a>-compliant identity provider with Kyma.   </p>\n<h2 id=\"serverless\">Serverless</h2>\n<p>The Kyma Serverless component allows you to reduce the implementation and operation effort of an application to the absolute minimum. Kyma Serverless provides a platform to run lightweight functions in a cost-efficient and scalable way using JavaScript and Node.js. Kyma Serverless is built on the <a href=\"http://kubeless.io/\" target=\"_blank\">Kubeless</a> framework, which allows you to deploy lambda functions,\nand uses the <a href=\"https://nats.io/\" target=\"_blank\">NATS</a> messaging system that monitors business events and triggers functions accordingly.  </p>\n<h2 id=\"monitoring\">Monitoring</h2>\n<p>Kyma comes bundled with tools that give you the most accurate and up-to-date monitoring data.  <a href=\"https://prometheus.io/\" target=\"_blank\">Prometheus</a> open source monitoring and alerting toolkit provides this data, which is consumed by different add-ons, including <a href=\"https://grafana.com/\" target=\"_blank\">Grafana</a> for analytics and monitoring, and <a href=\"https://prometheus.io/docs/alerting/alertmanager/\" target=\"_blank\">Alertmanager</a> for handling alerts.</p>\n<h2 id=\"tracing\">Tracing</h2>\n<p>The tracing in Kyma uses the <a href=\"https://github.com/jaegertracing\" target=\"_blank\">Jaeger</a> distributed tracing system. Use it to analyze performance by scrutinizing the path of the requests sent to and from your service. This information helps you optimize the latency and performance of your solution.</p>\n"
    },
    {
      "order": "005-environments",
      "title": "Environments",
      "type": "Details",
      "source":
        "<p>An Environment is a custom Kyma security and organizational unit based on the concept of Kubernetes <a href=\"https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/\" target=\"_blank\">Namespaces</a>. Kyma Environments allow you to divide the cluster\ninto smaller units to use for different purposes, such as development and testing.</p>\n<p>Kyma Environment is a user-created Namespace marked with the <code>env: &quot;true&quot;</code> label. The Kyma UI only displays the Namespaces marked with the <code>env: &quot;true&quot;</code> label.</p>\n<h2 id=\"default-kyma-namespaces\">Default Kyma Namespaces</h2>\n<p>Kyma comes configured with default Namespaces dedicated for system-related purposes. The user cannot modify or remove any of these Namespaces.</p>\n<ul>\n<li><code>kyma-system</code> - This Namespace contains all of the Kyma Core components.</li>\n<li><code>kyma-integration</code> - This Namespace contains all of the Application Connector components responsible for the integration of Kyma and external solutions.</li>\n<li><code>kyma-installer</code> - This Namespace contains all of the Kyma installer components, objects, and Secrets.</li>\n<li><code>istio-system</code> - This Namespace contains all of the Istio-related components.</li>\n</ul>\n<h2 id=\"environments-in-kyma\">Environments in Kyma</h2>\n<p>Kyma comes with three Environments ready for you to use. These environments are:</p>\n<ul>\n<li><code>production</code></li>\n<li><code>qa</code></li>\n<li><code>stage</code></li>\n</ul>\n<h2 id=\"create-a-new-environment\">Create a new Environment</h2>\n<p>To create a new Environment, create a Namespace and mark it with the <code>env: &quot;true&quot;</code> label. Use this command to do that in a single step:</p>\n<pre><code>$ cat &lt;&lt;EOF | kubectl create -f -\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: my-environment\n  labels:\n    env: &quot;true&quot;\nEOF\n</code></pre><p>Initially, the system deploys two template roles: <code>kyma-reader-role</code> and <code>kyma-admin-role</code>. The controller finds the template roles by filtering available roles in the namespace <code>kyma-system</code> by the label <code>env: &quot;true&quot;</code>. The controller copies these roles into the Environment.</p>\n"
    },
    {
      "order": "019-prereq-reasoning",
      "title": "Prerequisites reasoning",
      "type": "Details",
      "source":
        "<h2 id=\"hyperkit-driver\">Hyperkit Driver</h2>\n<p>Minikube can run on different VM drivers. The Hyperkit driver is the only driver on which Kyma is tested, making it a prerequisite.</p>\n<h2 id=\"minikube\">Minikube</h2>\n<p>To work with Kyma, use only the provided installation and deinstallation scripts. Kyma does not work on a basic Minikube cluster that you can start using the <code>minikube start</code> command or stop with the <code>minikube stop</code> command. If you do not need Kyma on Minikube anymore, remove the cluster with the <code>minikube delete</code> command.</p>\n"
    },
    {
      "order": "025-details-local-reinstallation",
      "title": "Reinstall Kyma",
      "type": "Details",
      "source":
        "<p>The custom scripts allow you to remove Kyma from a Minikube cluster, and reinstall Kyma without removing the cluster.</p>\n<blockquote>\n<p><strong>NOTE:</strong> These scripts do not delete the cluster from your Minikube. This allows you to quickly re-install Kyma.</p>\n</blockquote>\n<ol>\n<li><p>Use the <code>clean-up.sh</code> script to uninstall Kyma from the cluster. Run:</p>\n<pre><code>scripts/clean-up.sh\n</code></pre></li>\n<li><p>Run this script to reinstall Kyma on an existing cluster:</p>\n<pre><code>cmd/run.sh --skip-minikube-start\n</code></pre></li>\n</ol>\n"
    },
    {
      "order": "026-details-testing",
      "title": "Testing Kyma",
      "type": "Details",
      "source":
        "<p>For testing, the Kyma components use the Helm test concept. Place your test under the <code>templates</code> directory as a Pod definition that specifies a container with a given command to run.</p>\n<h2 id=\"add-a-new-test\">Add a new test</h2>\n<p>The system bases tests on the Helm broker concept with one modification: adding a Pod label. Before you create a test, see the official <a href=\"https://github.com/kubernetes/helm/blob/release-2.7/docs/chart_tests.md\" target=\"_blank\">Chart Tests</a> documentation. Then, add the <code>&quot;helm-chart-test&quot;: &quot;true&quot;</code> label to your Pod template.</p>\n<p>See the following example of a test prepared for Dex:</p>\n<pre><code># Chart tree\ndex\n├── Chart.yaml\n├── README.md\n├── templates\n│   ├── tests\n│   │   └── test-dex-connection.yaml\n│   ├── dex-deployment.yaml\n│   ├── dex-ingress.yaml\n│   ├── dex-rbac-role.yaml\n│   ├── dex-service.yaml\n│   ├── pre-install-dex-account.yaml\n│   ├── pre-install-dex-config-map.yaml\n│   └── pre-install-dex-secrets.yaml\n└── values.yaml\n</code></pre><p>The test adds a new <strong>test-dex-connection.yaml</strong> under the <code>templates/tests</code> directory.\nThis simple test calls the <code>Dex</code> endpoint with cURL, defined as follows:</p>\n<pre><code class=\"lang-yaml\">apiVersion: v1\nkind: Pod\nmetadata:\n  name: &quot;test-{{ template &quot;fullname&quot; . }}-connection-dex&quot;\n  annotations:\n    &quot;helm.sh/hook&quot;: test-success\n  labels:\n      &quot;helm-chart-test&quot;: &quot;true&quot; # ! Our customization\nspec:\n  hostNetwork: true\n  containers:\n  - name: &quot;test-{{ template &quot;fullname&quot; . }}-connection-dex&quot;\n    image: tutum/curl:alpine\n    command: [&quot;/usr/bin/curl&quot;]\n    args: [\n      &quot;--fail&quot;,\n      &quot;http://dex-service.{{ .Release.Namespace }}.svc.cluster.local:5556/.well-known/openid-configuration&quot;\n    ]\n  restartPolicy: Never\n</code></pre>\n<h2 id=\"test-execution\">Test execution</h2>\n<p>All tests created for <a href=\"../../../resources/core/\">core</a> charts run automatically after starting Kyma.\nIf any of the tests fail, the system prints the Pod logs in the terminal, then deletes all the Pods.</p>\n<blockquote>\n<p><strong>NOTE:</strong> If you run Kyma locally, by default, the system does not take into account the test&#39;s exit code. As a result, the system does not terminate Kyma Docker container, and you can still access it.\nTo force a termination in case of failing tests, use <code>--exit-on-test-fail</code> flag when executing <code>run.sh</code> script.</p>\n</blockquote>\n<p>CI propagates the exit status of tests. If any test fails, the whole CI job fails as well.</p>\n<p>Follow the same guidelines to add a test which is not a part of any <strong>core</strong> component. However, for test execution, see <strong>Run a test manually</strong> in this document.</p>\n<h3 id=\"run-a-test-manually\">Run a test manually</h3>\n<p>To run a test manually, use the <a href=\"../../../installation/scripts/testing.sh\">testing.sh</a> script, which runs all tests defined for <strong>core</strong> releases.\nIf any of the tests fail, the system prints the Pod logs in the terminal, then deletes all the Pods.</p>\n<p>Another option is to run a Helm test directly on your release.</p>\n<pre><code class=\"lang-bash\">$ helm test &lt;your_release_name&gt;\n</code></pre>\n<p>You can also run your test on custom releases. If you do this, remember to always delete the Pods after a test ends.</p>\n"
    },
    {
      "order": "027-details-charts",
      "title": "Charts",
      "type": "Details",
      "source":
        "<p>Kyma uses Helm charts to deliver single components and extensions, as well as the core components. This document contains information about the chart-related technical concepts, dependency management to use with Helm charts, and chart examples.</p>\n<h2 id=\"manage-dependencies-with-init-containers\">Manage dependencies with Init Containers</h2>\n<p>The <a href=\"https://github.com/kyma-project/community-new/blob/master/architecture-decision-records/adr-004-InitContainers_for_dependency_management.md\" target=\"_blank\">ARD#004</a> architecture decision record declares the use of Init Containers as the primary dependency mechanism.</p>\n<p><a href=\"https://kubernetes.io/docs/concepts/workloads/pods/init-containers/\" target=\"_blank\">Init Containers</a> present a set of distinctive behaviors:</p>\n<ul>\n<li>They always run to completion.</li>\n<li>They start sequentially, only after the preceding Init Container completes successfully.\nIf any of the Init Containers fails, the Pod restarts. This is always true, unless the <code>restartPolicy</code> equals <code>never</code>.</li>\n</ul>\n<p><a href=\"https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes\" target=\"_blank\">Readiness Probes</a> ensure that the essential containers are ready to handle requests before you expose them. At a minimum, probes are defined for every container accessible from outside of the Pod. It is recommended to pair the Init Containers with readiness probes to provide a basic dependency management solution.</p>\n<h2 id=\"examples\">Examples</h2>\n<p>Here are some examples:</p>\n<ol>\n<li>Generic</li>\n</ol>\n<pre><code class=\"lang-yaml\">apiVersion: apps/v1beta2\nkind: Deployment\nmetadata:\n  name: nginx-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:1.7.9\n        ports:\n        - containerPort: 80\n        readinessProbe:\n          httpGet:\n            path: /healthz\n            port: 80\n          initialDelaySeconds: 30\n          timeoutSeconds: 1\n</code></pre>\n<pre><code class=\"lang-yaml\">apiVersion: v1\nkind: Pod\nmetadata:\n  name: myapp-pod\nspec:\n  initContainers:\n  - name: init-myservice\n    image: busybox\n    command: [&#39;sh&#39;, &#39;-c&#39;, &#39;until nslookup nginx; do echo waiting for nginx; sleep 2; done;&#39;]\n  containers:\n  - name: myapp-container\n    image: busybox\n    command: [&#39;sh&#39;, &#39;-c&#39;, &#39;echo The app is running! &amp;&amp; sleep 3600&#39;]\n</code></pre>\n<ol>\n<li>Kyma</li>\n</ol>\n<pre><code class=\"lang-yaml\">apiVersion: extensions/v1beta1\nkind: Deployment\nmetadata:\n  name: helm-broker\n  labels:\n    app: helm-broker\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: helm-broker\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxUnavailable: 0\n  template:\n    metadata:\n      labels:\n        app: helm-broker\n    spec:\n\n      initContainers:\n      - name: init-helm-broker\n        image: eu.gcr.io/kyma-project/alpine-net:0.2.74\n        command: [&#39;sh&#39;, &#39;-c&#39;, &#39;until nc -zv core-catalog-controller-manager.kyma-system.svc.cluster.local 8080; do echo waiting for etcd service; sleep 2; done;&#39;]\n\n      containers:\n      - name: helm-broker\n        ports:\n        - containerPort: 6699\n        readinessProbe:\n          tcpSocket:\n            port: 6699\n          failureThreshold: 3\n          initialDelaySeconds: 10\n          periodSeconds: 3\n          successThreshold: 1\n          timeoutSeconds: 2\n</code></pre>\n<h2 id=\"support-for-the-helm-wait-flag\">Support for the Helm wait flag</h2>\n<p>High level Kyma components, such as <strong>core</strong>, come as Helm charts. These charts are installed as part of a single Helm release. To provide ordering for these core components, the Helm client runs with the <code>--wait</code> flag. As a result, Tiller waits for the readiness of all of the components, and then evaluates the readiness.</p>\n<p>For <code>Deployments</code>, set the strategy to <code>RollingUpdate</code> and set the <code>MaxUnavailable</code> value to a number lower than the number of replicas. This setting is necessary, as readiness in Helm v2.8.2 is fulfilled if the number of replicas in ready state is not lower than the expected number of replicas:</p>\n<pre><code>ReadyReplicas &gt;= TotalReplicas - MaxUnavailable\n</code></pre><h2 id=\"chart-installation-details\">Chart installation details</h2>\n<p>The Tiller server performs the chart installation process. This is the order of operations that happen during the chart installation:</p>\n<ul>\n<li>resolve values</li>\n<li>recursively gather all templates with the corresponding values</li>\n<li>sort all templates</li>\n<li>render all templates</li>\n<li>separate hooks and manifests from files into sorted lists</li>\n<li>aggregate all valid manifests from all sub-charts into a single manifest file</li>\n<li>execute PreInstall hooks</li>\n<li>create a release using the ReleaseModule API and, if requested, wait for the actual readiness of the resources</li>\n<li>execute PostInstall hooks</li>\n</ul>\n<h2 id=\"notes\">Notes</h2>\n<p>All notes are based on Helm v2.7.2 implementation and are subject to change in feature releases.</p>\n<ul>\n<li><p>Regardless of how complex a chart is, and regardless of the number of sub-charts it references or consists of, it&#39;s always evaluated as one. This means that each Helm release is compiled into a single Kubernetes manifest file when applied on API server.</p>\n</li>\n<li><p>Hooks are parsed in the same order as manifest files and returned as a single, global list for the entire chart. For each hook the weight is calculated as a part of this sort.</p>\n</li>\n<li><p>Manifests are sorted by <code>Kind</code>. You can find the list and the order of the resources on the Kubernetes <a href=\"https://github.com/kubernetes/helm/blob/v2.8.2/pkg/tiller/kind_sorter.go#L29\" target=\"_blank\">Tiller</a> website.</p>\n</li>\n</ul>\n<h2 id=\"glossary\">Glossary</h2>\n<ul>\n<li><strong>resource</strong> is any document in a chart recognized by Helm or Tiller. This includes manifests, hooks, and notes.</li>\n<li><strong>template</strong> is a valid Go template. Many of the resources are also Go templates.</li>\n</ul>\n"
    },
    {
      "order": "028-details-deploy-private-registry",
      "title": "How to deploy a Docker image from a private registry",
      "type": "Details",
      "source":
        "<h2 id=\"overview\">Overview</h2>\n<p>Docker is a free tool to deploy applications and servers. To run an application on Kyma, provide the application binary file as a Docker image located in a Docker registry. Use the <code>DockerHub</code> public registry to upload your Docker images for free access to the public. Use a private Docker registry to ensure privacy, increased security, and better availability.</p>\n<p>This document shows how to deploy a Docker image from your private Docker registry to the Kyma cluster.</p>\n<h2 id=\"details\">Details</h2>\n<p>The deployment to Kyma from a private registry differs from the deployment from a public registry. You must provide Secrets accessible in Kyma, and referenced in the <code>.yaml</code> deployment file. This section describes how to deploy an image from a private Docker registry to Kyma. Follow the deployment steps:</p>\n<ol>\n<li>Create a Secret resource.</li>\n<li>Write your deployment file.</li>\n<li>Submit the file to the Kyma cluster.</li>\n</ol>\n<h3 id=\"create-a-secret-for-your-private-registry\">Create a Secret for your private registry</h3>\n<p>A Secret resource passes your Docker registry credentials to the Kyma cluster in an encrypted form. For more information on Secrets, refer to the <a href=\"https://kubernetes.io/docs/concepts/configuration/secret/\" target=\"_blank\">Kubernetes documentation</a>.</p>\n<p>To create a Secret resource for your Docker registry, run the following command:</p>\n<pre><code class=\"lang-bash\">kubectl create secret docker-registry {secret-name} --docker-server={registry FQN} --docker-username={user-name} --docker-password={password} --docker-email={registry-email} --namespace={namespace}\n</code></pre>\n<p>Refer to the following example:</p>\n<pre><code class=\"lang-bash\">kubectl create secret docker-registry docker-registry-secret --docker-server=myregistry:5000 --docker-username=root --docker-password=password --docker-email=example@github.com --namespace=production\n</code></pre>\n<p>The Secret is associated with a specific Namespace. In the example, the Namespace is <code>production</code>. However, you can modify the Secret to point to any desired Namespace.</p>\n<h3 id=\"write-your-deployment-file\">Write your deployment file</h3>\n<ol>\n<li><p>Create the deployment file with the <code>.yml</code> extension and name it <code>deployment.yml</code>.</p>\n</li>\n<li><p>Describe your deployment in the <code>.yml</code> file. Refer to the following example:</p>\n</li>\n</ol>\n<pre><code class=\"lang-yaml\">apiVersion: apps/v1beta2\nkind: Deployment\nmetadata:\n  namespace: production # {production/stage/qa}\n  name: my-deployment # Specify the deployment name.\n  annotations:\n    sidecar.istio.io/inject: true\nspec:\n  replicas: 3 # Specify your replica - how many instances you want from that deployment.\n  selector:\n    matchLabels:\n      app: app-name # Specify the app label. It is optional but it is a good practice.\n  template:\n    metadata:\n      labels:\n        app: app-name # Specify app label. It is optional but it is a good practice.\n        version: v1 # Specify your version.\n    spec:\n      containers:\n      - name: container-name # Specify a meaningful container name.\n        image: myregistry:5000/user-name/image-name:latest # Specify your image {registry FQN/your-username/your-space/image-name:image-version}.\n        ports:\n          - containerPort: 80 # Specify the port to your image.\n      imagePullSecrets:\n        - name: docker-registry-secret # Specify the same Secret name you generated in the previous step for this Namespace.\n        - name: example-secret-name # Specify your Namespace Secret, named `example-secret-name`.\n</code></pre>\n<ol>\n<li>Submit you deployment file using this command:</li>\n</ol>\n<pre><code class=\"lang-bash\">kubectl apply -f deployment.yml\n</code></pre>\n<p>Your deployment is now running on the Kyma cluster.</p>\n"
    },
    {
      "order": "031-gs-local-installation",
      "title": "Local Kyma installation",
      "type": "Getting Started",
      "source":
        "<h2 id=\"overview\">Overview</h2>\n<p>This Getting Started guide instructs developers to quickly deploy Kyma locally on a Mac, Linux, or Windows. Kyma installs locally using a proprietary installer based on a Kubernetes operator.\nThe document provides the prerequisites, the instructions on how to install Kyma locally and verify the deployment, and the troubleshooting tips.</p>\n<h2 id=\"prerequisites\">Prerequisites</h2>\n<p>To run Kyma locally, clone this Git repository to your local machine and download these tools:</p>\n<ul>\n<li><a href=\"https://github.com/kubernetes/minikube\" target=\"_blank\">Minikube</a> 0.28.2</li>\n<li><a href=\"https://kubernetes.io/docs/tasks/tools/install-kubectl/\" target=\"_blank\">kubectl</a> 1.10.0</li>\n<li><a href=\"https://github.com/kubernetes/helm\" target=\"_blank\">Helm</a> 2.8.2</li>\n<li><a href=\"https://stedolan.github.io/jq/\" target=\"_blank\">jq</a></li>\n<li><a href=\"https://github.com/kubernetes/minikube/blob/master/docs/drivers.md#hyperkit-driver\" target=\"_blank\">Hyperkit driver</a> - Mac only</li>\n<li><a href=\"https://www.virtualbox.org/\" target=\"_blank\">Virtualbox</a> - Linux or Windows</li>\n<li>Hyper-V - Windows</li>\n</ul>\n<p>Read the <a href=\"019-prereq-reasoning.md\">prerequisite reasoning</a> document to learn why Kyma uses these tools.</p>\n<h2 id=\"setup-certificates\">Setup certificates</h2>\n<p>Kyma comes with a local wildcard self-signed <a href=\"../../../installation/certs/workspace/raw/server.crt\">certificate</a>. Trust it on the OS level for convenience. Alternatively, accept exceptions for each subdomain in your browser as you use Kyma.</p>\n<p>Follow these steps to &quot;always trust&quot; the Kyma certificate on macOS:</p>\n<ol>\n<li>Open the Keychain Access application. Select <strong>System</strong> from the <strong>Keychains</strong> menu.</li>\n<li>Go to <strong>File</strong>, select <strong>Import items...</strong>, and import the Kyma <a href=\"../../../installation/certs/workspace/raw/server.crt\">certificate</a>.</li>\n<li>Go to the <strong>Certificates</strong> view and find the <code>*.kyma.local</code> certificate you imported.</li>\n<li>Right-click the certificate and select <strong>Get Info</strong>.</li>\n<li>Expand the <strong>Trust</strong> list and set <strong>When using this certificate</strong> to <strong>Always trust</strong>.</li>\n<li>Close the certificate information window and enter your system password to confirm the changes.</li>\n</ol>\n<blockquote>\n<p><strong>NOTE:</strong></p>\n<ul>\n<li>The process is complete when you close the certificate information window and enter your password. You don&#39;t get the expected results if you try to use the certificate before completing this step.</li>\n<li>&quot;Always trusting&quot; the certificate does not work with Mozilla Firefox.</li>\n</ul>\n</blockquote>\n<h2 id=\"install-kyma-on-minikube\">Install Kyma on Minikube</h2>\n<blockquote>\n<p><strong>NOTE:</strong> Running the installation script deletes any previously existing cluster from your Minikube.</p>\n</blockquote>\n<ol>\n<li><p>Change the working directory to <code>installation</code>:</p>\n<pre><code class=\"lang-bash\">cd installation\n</code></pre>\n</li>\n<li><p>Depending on your operating system, run <code>run.sh</code> for Mac and Linux or <code>run.ps1</code> for Windows</p>\n<pre><code>cmd/run.sh\n</code></pre></li>\n</ol>\n<p>The <code>run.sh</code> script does not show the progress of the Kyma installation, which allows you to perform other tasks in the terminal window. However, to see the status of the Kyma installation, run this script after you set up the cluster and the installer:</p>\n<pre><code>scripts/is-installed.sh\n</code></pre><p>Read the <a href=\"025-details-local-reinstallation.md\">Reinstall Kyma</a> document to learn how to reinstall Kyma without deleting the cluster from Minikube.\nTo learn how to test Kyma, see the <a href=\"026-details-testing.md\">Testing Kyma</a> document.</p>\n<h3 id=\"custom-resource-file\">Custom Resource file</h3>\n<p>The Custom Resource file contains controls the Kyma installer, which is a proprietary solution based on the <a href=\"https://coreos.com/operators/\" target=\"_blank\">Kubernetes operator</a>. The file contains the basic information that defines Kyma installation.\nFind the custom resource template <a href=\"../../../installation/resources/installer-cr.yaml.tpl\">here</a>.</p>\n<h3 id=\"control-the-installation-process\">Control the installation process</h3>\n<p>To trigger the installation process, set the <strong>action</strong> label to <code>install</code> in the metadata of the Custom Resource with the installer configuration.\nTo trigger the deinstallation process, set the <strong>action</strong> label to <code>uninstall</code> in the metadata of the Custom Resource with the installer configuration.</p>\n<h3 id=\"generate-a-new-custom-resource-file\">Generate a new Custom Resource file</h3>\n<p>Use the <code>create-cr.sh</code> script to generate the Custom Resource file. The script accepts these arguments:</p>\n<ul>\n<li><code>--output</code> - mandatory. The location of the Custom Resource output file</li>\n<li><code>--url</code> - the URL of the Kyma package to install</li>\n<li><code>--version</code> - the Kyma version</li>\n<li><code>--ipaddr</code> - the load balancer IP</li>\n<li><code>--domain</code> - the instance domain</li>\n</ul>\n<p>For example:</p>\n<pre><code>$ ./installation/scripts/create-cr.sh --output kyma-cr.yaml --url {Kyma_TAR.GZ_URL} --version 0.0.1 --domain kyma.local\n</code></pre><h2 id=\"verify-the-deployment\">Verify the deployment</h2>\n<p>Follow the guidelines in the subsections to confirm that your Kubernetes API Server is up and running as expected.</p>\n<h3 id=\"access-kyma-with-cli\">Access Kyma with CLI</h3>\n<p>Verify the cluster deployment with the kubectl command line interface (CLI).</p>\n<p>Run this command to fetch all Pods in all Namespaces:</p>\n<pre><code class=\"lang-bash\">  kubectl get pods --all-namespaces\n</code></pre>\n<p>The command retrieves all Pods from all Namespaces, the status of the Pods, and their instance numbers. Check if the <strong>STATUS</strong> column shows <code>Running</code> for all Pods. If any of the Pods that you require do not start successfully, perform the installation again.</p>\n<h3 id=\"access-the-kyma-console\">Access the Kyma console</h3>\n<p>Access your local Kyma instance through <a href=\"https://console.kyma.local/\" target=\"_blank\">this</a> link.</p>\n<ul>\n<li><p>Click <strong>Login with Email</strong> and sign in with the <code>admin@kyma.cx</code> email address and the generic password from the <a href=\"../../../resources/dex/templates/dex-config-map.yaml#L51\">Dex ConfigMap</a> file.</p>\n</li>\n<li><p>Click the <strong>Environments</strong> section and select an Environment from the drop-down menu to explore Kyma further.</p>\n</li>\n</ul>\n<h3 id=\"access-the-kubernetes-dashboard\">Access the Kubernetes Dashboard</h3>\n<p>Additionally, confirm that you can access your Kubernetes Dashboard. Run the following command to check the IP address on which Minikube is running:</p>\n<pre><code class=\"lang-bash\">minikube ip\n</code></pre>\n<p>The URL of your Kubernetes Dashboard looks similar to this:</p>\n<pre><code>http://{ip-address}:30000\n</code></pre><p>See the example of the website address:</p>\n<pre><code>http://192.168.64.44:30000\n</code></pre><h2 id=\"troubleshooting\">Troubleshooting</h2>\n<p>If the installer does not respond as expected, check the installation status using the <code>is-installed.sh</code> script with the <code>--verbose</code> flag added. Run:</p>\n<pre><code>scripts/is-installed.sh --verbose\n</code></pre>"
    },
    {
      "order": "032-gs-sample-service-deployment-to-local",
      "title": "Sample service deployment on local",
      "type": "Getting Started",
      "source":
        "<h2 id=\"overview\">Overview</h2>\n<p>This Getting Started guide is intended for the developers who want to quickly learn how to deploy a sample service and test it with Kyma installed locally on Mac.</p>\n<p>This guide uses a standalone sample service written in the <a href=\"http://golang.org\" target=\"_blank\">Go</a> language .</p>\n<h2 id=\"prerequisites\">Prerequisites</h2>\n<p>To use the Kyma cluster and install the example, download these tools:</p>\n<ul>\n<li><a href=\"https://kubernetes.io/docs/tasks/tools/install-kubectl/\" target=\"_blank\">kubectl</a> 1.10.0</li>\n<li><a href=\"https://github.com/curl/curl\" target=\"_blank\">curl</a></li>\n</ul>\n<h2 id=\"steps\">Steps</h2>\n<h3 id=\"deploy-and-expose-a-sample-standalone-service\">Deploy and expose a sample standalone service</h3>\n<p>Follow these steps:</p>\n<ol>\n<li><p>Deploy the sample service to any of your Environments. Use the <code>stage</code> Environment for this guide:</p>\n<pre><code class=\"lang-bash\">kubectl create -n stage -f https://github.com/raw/kyma-project/examples/master/http-db-service/deployment/deployment.yaml\n</code></pre>\n</li>\n<li><p>Create an unsecured API for your example service:</p>\n<pre><code class=\"lang-bash\">kubectl apply -n stage -f https://github.com/raw/kyma-project/examples/master/gateway/service/api-without-auth.yaml\n</code></pre>\n</li>\n<li><p>Add the IP address of Minikube to the <code>hosts</code> file on your local machine for your APIs:</p>\n<pre><code class=\"lang-bash\">$ echo &quot;$(minikube ip) http-db-service.kyma.local&quot; | sudo tee -a /etc/hosts\n</code></pre>\n</li>\n<li><p>Access the service using the following call:</p>\n<pre><code class=\"lang-bash\">curl -ik https://http-db-service.kyma.local/orders\n</code></pre>\n<p> The system returns a response similar to the following:</p>\n<pre><code>HTTP/2 200\ncontent-type: application/json;charset=UTF-8\nvary: Origin\ndate: Mon, 01 Jun 2018 00:00:00 GMT\ncontent-length: 2\nx-envoy-upstream-service-time: 131\nserver: envoy\n\n[]\n</code></pre></li>\n</ol>\n<h3 id=\"update-your-service-s-api-to-secure-it\">Update your service&#39;s API to secure it</h3>\n<p>Run the following command:</p>\n<pre><code class=\"lang-bash\">   kubectl apply -n stage -f https://github.com/raw/kyma-project/examples/master/gateway/service/api-with-auth.yaml\n</code></pre>\n<p>After you apply this update, you must include a valid bearer ID token in the Authorization header to access the service.</p>\n<blockquote>\n<p><strong>NOTE:</strong> The update might take some time.</p>\n</blockquote>\n"
    },
    {
      "order": "033-gs-sample-service-deployment-to-cluster",
      "title": "Sample service deployment on a cluster",
      "type": "Getting Started",
      "source":
        "<h2 id=\"overview\">Overview</h2>\n<p>This Getting Started guide is intended for the developers who want to quickly learn how to deploy a sample service and test it with the Kyma cluster.</p>\n<p>This guide uses a standalone sample service written in the <a href=\"http://golang.org\" target=\"_blank\">Go</a> language.</p>\n<h2 id=\"prerequisites\">Prerequisites</h2>\n<p>To use the Kyma cluster and install the example, download these tools:</p>\n<ul>\n<li><a href=\"https://kubernetes.io/docs/tasks/tools/install-kubectl/\" target=\"_blank\">kubectl</a> 1.10.0</li>\n<li><a href=\"https://github.com/curl/curl\" target=\"_blank\">curl</a></li>\n</ul>\n<h2 id=\"steps\">Steps</h2>\n<h3 id=\"download-configuration-for-kubectl\">Download configuration for kubectl</h3>\n<p>Follow these steps to download <strong>kubeconfig</strong> and configure kubectl to access the Kyma cluster:</p>\n<ol>\n<li>Access the Console UI and download the <strong>kubectl</strong> file from the settings page.</li>\n<li>Place downloaded file in the following location: <code>$HOME/.kube/kubeconfig</code>.</li>\n<li>Point <strong>kubectl</strong> to the configuration file using the terminal: <code>export KUBECONFIG=$HOME/.kube/kubeconfig</code>.</li>\n<li>Confirm <strong>kubectl</strong> is configured to use your cluster: <code>kubectl cluster-info</code>.</li>\n</ol>\n<h3 id=\"set-the-cluster-domain-variable\">Set the cluster domain variable</h3>\n<p>The commands throughout this guide use URLs that require you to provide the domain of the cluster which you are using. To complete this configuration, set the variable <code>yourClusterDomain</code> to the domain of your cluster.</p>\n<p>For example if your cluster&#39;s domain is &#39;demo.cluster.kyma.cx&#39; then run the following command:</p>\n<pre><code class=\"lang-bash\">   export yourClusterDomain=&#39;demo.cluster.kyma.cx&#39;\n</code></pre>\n<h3 id=\"deploy-and-expose-a-sample-standalone-service\">Deploy and expose a sample standalone service</h3>\n<p>Follow these steps:</p>\n<ol>\n<li><p>Deploy the sample service to any of your Environments. Use the <code>stage</code> Environment for this guide:</p>\n<pre><code class=\"lang-bash\">kubectl create -n stage -f https://minio.$yourClusterDomain/content/root/kyma/assets/deployment.yaml\n</code></pre>\n</li>\n<li><p>Create an unsecured API for your service:</p>\n<pre><code class=\"lang-bash\">curl -k https://minio.$yourClusterDomain/content/root/kyma/assets/api-without-auth.yaml |  sed &quot;s/.kyma.local/.$yourClusterDomain/&quot; | kubectl apply -n stage -f -\n</code></pre>\n</li>\n<li><p>Access the service using the following call:</p>\n<pre><code class=\"lang-bash\">curl -ik https://http-db-service.$yourClusterDomain/orders\n</code></pre>\n<p>The system returns a response similar to the following:</p>\n<pre><code>HTTP/2 200\ncontent-type: application/json;charset=UTF-8\nvary: Origin\ndate: Mon, 01 Jun 2018 00:00:00 GMT\ncontent-length: 2\nx-envoy-upstream-service-time: 131\nserver: envoy\n\n[]\n</code></pre></li>\n</ol>\n<h3 id=\"update-your-service-s-api-to-secure-it\">Update your service&#39;s API to secure it</h3>\n<p>Run the following command:</p>\n<pre><code class=\"lang-bash\">   curl -k https://minio.$yourClusterDomain/content/root/kyma/assets/api-with-auth.yaml |  sed &quot;s/.kyma.local/.$yourClusterDomain/&quot; | kubectl apply -n stage -f -\n</code></pre>\n<p>After you apply this update, you must include a valid bearer ID token in the Authorization header to access the service.</p>\n<blockquote>\n<p><strong>NOTE:</strong> The update might take some time.</p>\n</blockquote>\n"
    },
    {
      "order": "034-gs-local-develop-no-docker",
      "title": "Develop a service locally without using Docker",
      "type": "Getting Started",
      "source":
        "<h2 id=\"overview\">Overview</h2>\n<p>You can develop services in the local Kyma installation without extensive Docker knowledge or a need to build and publish a Docker image. The <code>minikube mount</code> feature allows you to mount a directory from your local disk into the local Kubernetes cluster.</p>\n<p>This guide shows how to use this feature, using the service example implemented in Golang.</p>\n<h2 id=\"prerequisites\">Prerequisites</h2>\n<p>Install <a href=\"https://golang.org/dl/\" target=\"_blank\">Golang</a>.</p>\n<h2 id=\"steps\">Steps</h2>\n<h3 id=\"install-the-example-on-your-local-machine\">Install the example on your local machine</h3>\n<ol>\n<li>Install the example:<pre><code class=\"lang-shell\">go get -insecure github.com/kyma-project/examples/http-db-service\n</code></pre>\n</li>\n<li>Navigate to installed example and the <code>http-db-service</code> folder inside it:<pre><code class=\"lang-shell\">cd ~/go/src/github.com/kyma-project/examples/http-db-service\n</code></pre>\n</li>\n<li>Build the executable to run the application:<pre><code class=\"lang-shell\">CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o main .\n</code></pre>\n</li>\n</ol>\n<h3 id=\"mount-the-example-directory-into-minikube\">Mount the example directory into Minikube</h3>\n<p>For this step, you need a running local Kyma instance. Read the <a href=\"031-gs-local-installation.md\">Local Kyma installation</a> Getting Started guide to learn how to install Kyma locally.</p>\n<ol>\n<li>Open the terminal window. Do not close it until the development finishes.</li>\n<li>Mount your local drive into Minikube:<pre><code class=\"lang-shell\"># Use the following pattern:\nminikube mount {LOCAL_DIR_PATH}:{CLUSTER_DIR_PATH}`\n# To follow this guide, call:\nminikube mount ~/go/src/github.com/kyma-project/examples/http-db-service:/go/src/github.com/kyma-project/examples/http-db-service\n</code></pre>\n</li>\n</ol>\n<p>See the example and expected result:</p>\n<pre><code class=\"lang-shell\"># Terminal 1\n$ minikube mount ~/go/src/github.com/kyma-project/examples/http-db-service:/go/src/github.com/kyma-project/examples/http-db-service\n\nMounting /Users/{USERNAME}/go/src/github.com/kyma-project/examples/http-db-service into /go/src/github.com/kyma-project/examples/http-db-service on the minikube VM\nThis daemon process must stay alive for the mount to still be accessible...\nufs starting\n</code></pre>\n<h3 id=\"run-your-local-service-inside-minikube\">Run your local service inside Minikube</h3>\n<ol>\n<li>Create Pod that uses the base Golang image to run your executable located on your local machine:<pre><code class=\"lang-shell\"># Terminal 2\nkubectl run mydevpod --image=golang:1.9.2-alpine --restart=Never -n stage --overrides=&#39;\n{\n&quot;spec&quot;:{\n   &quot;containers&quot;:[\n      {\n         &quot;name&quot;:&quot;mydevpod&quot;,\n         &quot;image&quot;:&quot;golang:1.9.2-alpine&quot;,\n         &quot;command&quot;: [&quot;./main&quot;],\n         &quot;workingDir&quot;:&quot;/go/src/github.com/kyma-project/examples/http-db-service&quot;,\n         &quot;volumeMounts&quot;:[\n            {\n               &quot;mountPath&quot;:&quot;/go/src/github.com/kyma-project/examples/http-db-service&quot;,\n               &quot;name&quot;:&quot;local-disk-mount&quot;\n            }\n         ]\n      }\n   ],\n   &quot;volumes&quot;:[\n      {\n         &quot;name&quot;:&quot;local-disk-mount&quot;,\n         &quot;hostPath&quot;:{\n            &quot;path&quot;:&quot;/go/src/github.com/kyma-project/examples/http-db-service&quot;\n         }\n      }\n   ]\n}\n}\n&#39;\n</code></pre>\n</li>\n<li>Expose the Pod as a service from Minikube to verify it:<pre><code class=\"lang-shell\">kubectl expose pod mydevpod --name=mypodservice --port=8017 --type=NodePort -n stage\n</code></pre>\n</li>\n<li>Check the Minikube IP address and Port, and use them to access your service.<pre><code class=\"lang-shell\"># Get the IP address.\nminikube ip\n# See the example result: 192.168.64.44\n# Check the Port.\nkubectl get services -n stage\n# See the example result: mypodservice  NodePort 10.104.164.115  &lt;none&gt;  8017:32226/TCP  5m\n</code></pre>\n</li>\n<li>Call the service from your terminal.<pre><code class=\"lang-shell\">curl {minikube ip}:{port}/orders -v\n# See the example: curl http://192.168.64.44:32226/orders -v\n# The command returns an empty array.\n</code></pre>\n</li>\n</ol>\n<h3 id=\"modify-the-code-locally-and-see-the-results-immediately-in-minikube\">Modify the code locally and see the results immediately in Minikube</h3>\n<ol>\n<li>Edit the <code>main.go</code> file by adding a new <code>test</code> endpoint to the <code>startService</code> function<pre><code class=\"lang-go\">router.HandleFunc(&quot;/test&quot;, func (w http.ResponseWriter, r *http.Request) {\n w.Write([]byte(&quot;test&quot;))\n})\n</code></pre>\n</li>\n<li>Build a new executable to run the application inside Minikube:<pre><code class=\"lang-shell\">CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o main .\n</code></pre>\n</li>\n<li>Replace the existing Pod with the new version:<pre><code class=\"lang-shell\">kubectl get pod mydevpod -n stage -o yaml | kubectl replace --force -f -\n</code></pre>\n</li>\n<li>Call the new <code>test</code> endpoint of the service from your terminal. The command returns the <code>Test</code> string:<pre><code class=\"lang-shell\">curl http://192.168.64.44:32226/test -v\n</code></pre>\n</li>\n</ol>\n"
    },
    {
      "order": "035-gs-publish-service-image-and-deploy",
      "title": "Publish a service Docker image and deploy it to Kyma",
      "type": "Getting Started",
      "source":
        "<h2 id=\"overview\">Overview</h2>\n<p>In the <a href=\"034-gs-local-develop-no-docker.md\">Getting Started</a> guide for local development of a service, you can learn how to develop a service locally. You can immediately see all the changes made in the local Kyma installation based on Minikube, without building a Docker image and publishing it to a Docker registry, such as the Docker Hub.</p>\n<p>Using the same example service, this guide explains how to build a Docker image for your service, publish it to the Docker registry, and deploy it to the local Kyma installation. The instructions base on Minikube, but you can also use the image that you create, and the Kubernetes resource definitions that you use on the Kyma cluster.</p>\n<blockquote>\n<p><strong>NOTE:</strong> The deployment works both on local Kyma installation and on the Kyma cluster.</p>\n</blockquote>\n<h2 id=\"steps\">Steps</h2>\n<h3 id=\"build-a-docker-image\">Build a Docker image</h3>\n<p>The <code>http-db-service</code> example used in this guide provides you with the <code>Dockerfile</code> necessary for building Docker images. Examine the <code>Dockerfile</code> to learn how it looks and how it uses the Docker Multistaging feature, but do not use it one-to-one for production. There might be custom <code>LABEL</code> attributes with values to override.</p>\n<ol>\n<li>In your terminal, go to the <code>examples/http-db-service</code> directory. If you did not follow the <a href=\"034-gs-local-develop-no-docker.md\">local service development</a> guide and you do not have this directory locally, get the <code>http-db-service</code> example from the <a href=\"https://github.com/kyma-project/examples\" target=\"_blank\">examples</a> repository.</li>\n<li>Run the build with <code>./build.sh</code>.</li>\n</ol>\n<blockquote>\n<p><strong>NOTE:</strong> Ensure that the new image builds and is available in your local Docker registry by calling <code>docker images</code>. Find an image called <code>example-http-db-service</code> and tagged as <code>latest</code>.</p>\n</blockquote>\n<h3 id=\"register-the-image-in-the-docker-hub\">Register the image in the Docker Hub</h3>\n<p>This guide bases on Docker Hub. However, there are many other Docker registries available. You can use a private Docker registry, but it must be available in the Internet. For more details about using a private Docker registry, see <a href=\"028-details-deploy-private-registry.md\">this</a> document.</p>\n<ol>\n<li>Open the <a href=\"https://hub.docker.com/\" target=\"_blank\">Docker Hub</a> webpage.</li>\n<li>Provide all of the required details and sign up.</li>\n</ol>\n<h3 id=\"sign-in-to-the-docker-hub-registry-in-the-terminal\">Sign in to the Docker Hub registry in the terminal</h3>\n<ol>\n<li>Call <code>docker login</code>.</li>\n<li>Provide the username and password, and select the <code>ENTER</code> key.</li>\n</ol>\n<h3 id=\"push-the-image-to-the-docker-hub\">Push the image to the Docker Hub</h3>\n<ol>\n<li>Tag the local image with a proper name required in the registry: <code>docker tag example-http-db-service {username}/example-http-db-service:0.0.1</code>.</li>\n<li>Push the image to the registry: <code>docker push {username}/example-http-db-service:0.0.1</code>.\n```shell\n#This is how it looks in the terminal</li>\n</ol>\n<p>The push refers to repository [docker.io/{username}/example-http-db-service]\n4302273b9e11: Pushed\n5835bd463c0e: Pushed\n0.0.1: digest: sha256:9ec28342806f50b92c9b42fa36d979c0454aafcdda6845b362e2efb9816d1439 size: 734\n```</p>\n<blockquote>\n<p><strong>NOTE:</strong> To verify if the image is successfully published, check if it is available online at the following address: <code>https://hub.docker.com/r/{username}/example-http-db-service/</code></p>\n</blockquote>\n<h3 id=\"deploy-to-kyma\">Deploy to Kyma</h3>\n<p>The <code>http-db-service</code> example contains sample Kubernetes resource definitions needed for the basic Kyma deployment. Find them in the <code>deployment</code> folder. Perform the following modifications to use your newly-published image in the local Kyma installation:</p>\n<ol>\n<li>Go to the <code>deployment</code> directory.</li>\n<li>Edit the <code>deployment.yaml</code> file. Change the <strong>image</strong> attribute to <code>{username}/example-http-db-service:0.0.1</code>.</li>\n<li>Create the new resources in local Kyma using these commands: <code>kubectl create -f deployment.yaml -n stage &amp;&amp; kubectl create -f ingress.yaml -n stage</code>.</li>\n<li>Edit your <code>/etc/hosts</code> to add the new <code>http-db-service.kyma.local</code> host to the list of hosts associated with your <code>minikube ip</code>. Follow these steps:<ul>\n<li>Open a terminal window and run: <code>sudo vim /etc/hosts</code></li>\n<li>Select the <strong>i</strong> key to insert a new line at the top of the file.</li>\n<li>Add this line: <code>{YOUR.MINIKUBE.IP} http-db-service.kyma.local</code></li>\n<li>Type <code>:wq</code> and select the <strong>Enter</strong> key to save the changes.</li>\n</ul>\n</li>\n<li>Run this command to check if you can access the service: <code>curl https://http-db-service.kyma.local/orders</code>. The response should return an empty array.</li>\n</ol>\n"
    }
  ]
}
